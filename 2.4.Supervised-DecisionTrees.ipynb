{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5ANp2r_H1p-"
   },
   "source": [
    "# √Årboles de decisi√≥n\n",
    "\n",
    "##  Cristina G√≥mez Alonso, Carlos Tessier\n",
    "\n",
    "En este notebook utilizaremos como referencia el material de Aurelien G√©ron, sintetizado por Akranz, para explicar c√≥mo entrenar, validar y realizar predicciones con **√°rboles de decisi√≥n** utilizando el dataset *Iris* y la librer√≠a **Scikit-learn**.\n",
    "\n",
    "El dataset *Iris* es un conjunto cl√°sico procedente del **UCI Machine Learning Repository**:\n",
    "[https://archive.ics.uci.edu/ml/datasets/iris](https://archive.ics.uci.edu/ml/datasets/iris)\n",
    "\n",
    "A continuaci√≥n revisaremos el algoritmo de entrenamiento **CART**, que es el que emplea `scikit-learn`, veremos c√≥mo **regularizar** √°rboles para evitar sobreajuste y c√≥mo utilizarlos tambi√©n en **tareas de regresi√≥n**. Para finalizar, analizaremos varias **limitaciones** de los √°rboles de decisi√≥n y en qu√© situaciones no son la mejor opci√≥n.\n",
    "\n",
    "## ¬øQu√© son los √Årboles de Decisi√≥n?\n",
    "\n",
    "Un √°rbol de decisi√≥n es una estructura que representa, de forma gr√°fica e interpretable, una serie de decisiones basadas en condiciones sobre las caracter√≠sticas del conjunto de datos. Es un algoritmo de **aprendizaje supervisado** muy usado, capaz de resolver tanto **clasificaci√≥n** como **regresi√≥n**, y destaca por su simplicidad e interpretabilidad.\n",
    "\n",
    "![arbol de decisi√≥n](https://miro.medium.com/v2/resize:fit:640/format:webp/1*BEH9fghOd9iYeGu8obk3PQ.png)\n",
    "\n",
    "Principales caracter√≠sticas de los √°rboles de decisi√≥n:\n",
    "\n",
    "* Clasifican los datos a partir de condiciones basadas en los atributos.\n",
    "* Son una t√©cnica de clasificaci√≥n muy extendida en machine learning.\n",
    "* Son modelos f√°ciles de interpretar, incluso por personas no expertas.\n",
    "* Tambi√©n pueden utilizarse en regresi√≥n para estimar valores num√©ricos (ventas mensuales, precio de un veh√≠culo, etc.).\n",
    "\n",
    "M√°s informaci√≥n:\n",
    "\n",
    "* [Wikipedia ‚Äî Decision Tree Learning](https://en.wikipedia.org/wiki/Decision_tree_learning)\n",
    "* [Tutorial de Kaggle](https://www.kaggle.com/prashant111/decision-tree-classifier-tutorial)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## √çndice Gini\n",
    "\n",
    "El √≠ndice Gini es la funci√≥n de coste utilizada por defecto para evaluar la calidad de las divisiones en un √°rbol de decisi√≥n.\n",
    "\n",
    "Una divisi√≥n en el conjunto de datos se define por un atributo de entrada y un umbral para dicho atributo, lo que permite separar los datos de entrenamiento en dos subconjuntos.\n",
    "\n",
    "El valor del √≠ndice Gini mide el **grado de impureza** de los nodos resultantes, es decir, cu√°n mezcladas est√°n las clases en cada subconjunto.\n",
    "Una separaci√≥n perfecta produce un √≠ndice Gini de **0**, mientras que la m√°xima impureza en un problema de **dos clases** se da cuando las clases est√°n repartidas al 50 %, produciendo un valor de **0,5**.\n",
    "\n",
    "---\n",
    "\n",
    "## Entropy\n",
    "\n",
    "`Entropy` es otra medida de impureza utilizada en √°rboles de decisi√≥n, basada en la **teor√≠a de la informaci√≥n**. Mientras que el √≠ndice Gini mide la probabilidad de error al clasificar un elemento al azar, `entropy` mide la **incertidumbre** del sistema.\n",
    "\n",
    "En la pr√°ctica:\n",
    "\n",
    "* **Gini** es **m√°s r√°pido de calcular** y por eso se usa por defecto en muchas implementaciones.\n",
    "* **Entropy** es **m√°s sensible a cambios en la distribuci√≥n de las clases**.\n",
    "* Ambos criterios suelen producir **√°rboles muy similares**.\n",
    "* No existe un criterio universalmente mejor: la diferencia suele ser **peque√±a y dependiente del problema**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importaci√≥n de paquetes y dataset\n",
    "\n",
    "Para entender los √°rboles de decisi√≥n, comencemos por construir uno y consultar sus predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GRmElfIEH1qD"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EX8X2GNeH1qF"
   },
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "Lel1EicRH1qG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Divisi√≥n del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQBhwwuNH1qG",
    "outputId": "022f70f0-f1d7-4b57-8548-d05d5f1c9d7f"
   },
   "outputs": [],
   "source": [
    "X = iris.data [:, 2:]  # Use only petal length and petal width\n",
    "y = iris.target\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "8UkZGcu4H1qH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Creaci√≥n del modelo de √Årboles de decisi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JVG44ut1H1qI"
   },
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "gxA9xixJH1qJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1wrI3S6-H1qK",
    "outputId": "74e8590e-b7aa-492f-9255-8699abf1cec6"
   },
   "outputs": [],
   "source": [
    "tree_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "y2qkCy-BH1qK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5. Visualizaci√≥n del √°rbol de decisi√≥n\n",
    "\n",
    "Podemos visualizar el √°rbol de decisiones utilizando el m√©todo export_graphiz() para exportar un archivo de representaci√≥n gr√°fica y luego transformarlo a png:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Set the figure size so the tree is legible\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot the tree\n",
    "plot_tree(tree_clf, \n",
    "          filled=True, \n",
    "          feature_names=iris.feature_names[2:],\n",
    "          class_names=iris.target_names,\n",
    "          rounded=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9tBJcb3H1qN"
   },
   "source": [
    "\n",
    "\n",
    "## 8. Realizaci√≥n de predicciones ‚Äî Versi√≥n revisada para el alumnado\n",
    "\n",
    "Para clasificar un nuevo dato con un √°rbol de decisi√≥n seguimos un proceso muy directo: empezamos en el nodo ra√≠z (la parte superior del √°rbol) y vamos respondiendo las preguntas binarias que aparecen en cada nodo. En cada paso avanzamos hacia la rama que corresponde a la condici√≥n que se cumple. Cuando llegamos a una hoja, esa hoja indica la clase final que el modelo asigna al dato.\n",
    "\n",
    "Una ventaja importante de los √°rboles de decisi√≥n es que **apenas necesitan preparaci√≥n de datos**: no es necesario escalar ni normalizar las variables, ya que las divisiones se basan en valores umbral y no en distancias.\n",
    "\n",
    "Cada nodo del √°rbol incluye varios atributos que ayudan a interpretar c√≥mo est√° tomando decisiones:\n",
    "\n",
    "* **samples (muestras)**: cu√°ntas instancias del conjunto de entrenamiento llegaron hasta ese nodo.\n",
    "* **value (valor)**: cu√°ntas muestras hay de cada clase dentro del nodo.\n",
    "* **gini**: medida de impureza. Si un nodo tiene solo una clase, su impureza es 0 (es un nodo ‚Äúpuro‚Äù).\n",
    "\n",
    "El √≠ndice Gini del nodo ( i ) se calcula mediante:\n",
    "\n",
    "$\n",
    "G_i = 1 - \\sum_{k=1}^{n} p_{i,k}^2\n",
    "$]$\n",
    "\n",
    "donde $ p_{i,k} $ es la proporci√≥n de muestras de la clase $ k $ dentro del nodo. En nuestro caso, $ k \\in {1,2,3} $.\n",
    "\n",
    "En `scikit-learn`, los √°rboles se entrenan con el algoritmo **CART**, que siempre genera √°rboles binarios: cada nodo de decisi√≥n tiene dos ramas. Otros algoritmos cl√°sicos, como **ID3**, s√≠ pueden crear nodos con m√°s de dos hijos.\n",
    "\n",
    "En la figura siguiente se aprecia c√≥mo un √°rbol va creando divisiones rectangulares en el espacio de caracter√≠sticas. Este comportamiento hace que los l√≠mites de decisi√≥n tengan forma de l√≠neas rectas y zonas rectangulares:\n",
    "\n",
    "![Boundaries](https://qu4nt.github.io/sklearn-doc-es/_images/sphx_glr_plot_iris_dtc_001.png)\n",
    "\n",
    "En general, los √°rboles de decisi√≥n:\n",
    "\n",
    "* son **intuitivos**\n",
    "* sus predicciones se pueden **interpretar f√°cilmente**\n",
    "* se consideran modelos de **‚Äúcaja blanca‚Äù**\n",
    "\n",
    "En contraste, m√©todos como **Random Forest** o las **redes neuronales profundas** se consideran modelos de **‚Äúcaja negra‚Äù**, ya que resulta mucho m√°s dif√≠cil interpretar c√≥mo llegan a sus decisiones internas.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uc-L7UPaH1qO"
   },
   "source": [
    "\n",
    "### 8.1. Estimando las probabilidades de pertenencia a cada clase\n",
    "\n",
    "Un √°rbol de decisi√≥n tambi√©n permite **estimar la probabilidad** de que una instancia pertenezca a cada clase. Para ello, toma la **hoja** en la que cae el dato y calcula la probabilidad como:\n",
    "\n",
    "> proporci√≥n de muestras de esa clase\n",
    "> entre el total de muestras presentes en la hoja.\n",
    "\n",
    "En `scikit-learn`, estas probabilidades pueden consultarse con el m√©todo `predict_proba()`.\n",
    "\n",
    "Por ejemplo, si introducimos una flor con **longitud de p√©talo = 5** y **ancho de p√©talo = 1.5**, el √°rbol puede devolver algo como:\n",
    "\n",
    "* Clase 0 ‚Üí 0.00\n",
    "* Clase 1 ‚Üí 0.90\n",
    "* Clase 2 ‚Üí 0.09\n",
    "\n",
    "Lo que significa que, seg√∫n el modelo, la clase m√°s probable es la **clase 1**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lk7vr2DOH1qP",
    "outputId": "c6f682db-cada-47b5-d433-d1933566bb6e"
   },
   "outputs": [],
   "source": [
    "tree_clf.predict_proba([[5, 1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwd8tLEWH1qP",
    "outputId": "3149918c-42fa-436d-d71d-7f49212293e1"
   },
   "outputs": [],
   "source": [
    "tree_clf.predict([[5, 1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKze1MLoH1qP"
   },
   "source": [
    "\n",
    "**Nota:** obtendremos la misma probabilidad para cualquier punto que caiga en la **misma hoja** del √°rbol. Aunque el nuevo dato est√© m√°s cerca o m√°s lejos de los l√≠mites de decisi√≥n (*decision boundaries*), la probabilidad no cambia, porque todas las muestras dentro de una misma hoja comparten la misma distribuci√≥n de clases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Regularizaci√≥n y sobreajuste en √Årboles de Decisi√≥n\n",
    "\n",
    "### ¬øPor qu√© los √°rboles sobreajustan?\n",
    "\n",
    "Los √°rboles de decisi√≥n tienden a **crecer demasiado** si no se les pone l√≠mite. Un √°rbol sin restricciones seguir√° dividi√©ndose hasta separar completamente las muestras del conjunto de entrenamiento. Esto suele producir:\n",
    "\n",
    "* **Exactitud perfecta en entrenamiento** (accuracy = 1.0)\n",
    "* **Peor rendimiento en test**, porque el √°rbol aprende ruido y particularidades del dataset, no patrones generales.\n",
    "\n",
    "Ejemplo simple con *Iris*:\n",
    "\n",
    "```python\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", clf.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", clf.score(X_test, y_test))\n",
    "```\n",
    "\n",
    "Salida t√≠pica:\n",
    "\n",
    "```\n",
    "Train accuracy: 1.0\n",
    "Test accuracy: 0.88\n",
    "```\n",
    "\n",
    "La diferencia entre ambos valores indica **overfitting**.\n",
    "\n",
    "---\n",
    "\n",
    "## ¬øC√≥mo evitar el sobreajuste?\n",
    "\n",
    "La soluci√≥n es **controlar la complejidad del √°rbol** mediante **hiperpar√°metros de regularizaci√≥n**. \n",
    "\n",
    "### Ejemplo visual: √°rbol sin podar vs. √°rbol podado\n",
    "\n",
    "En los √°rboles de decisi√≥n, **podar (pruning)** consiste en eliminar ramas que aportan poca informaci√≥n o que no mejoran la capacidad predictiva del modelo. El objetivo es obtener un √°rbol **m√°s simple**, **m√°s generalizable** y con **menor riesgo de sobreajuste**.\n",
    "\n",
    "![ejemplo pruning](https://miro.medium.com/v2/resize:fit:720/format:webp/1*WQfd2tteLlic7-pu_FxjfQ.png)\n",
    "\n",
    "Este ejemplo muestra claramente la diferencia entre ambos modelos:\n",
    "\n",
    "* **√Årbol sin podar:**\n",
    "\n",
    "  * Tiene m√°s nodos y m√°s profundidad.\n",
    "  * Captura el ruido del conjunto de entrenamiento.\n",
    "  * Presenta mayor varianza y tiende a sobreajustar.\n",
    "\n",
    "* **√Årbol podado:**\n",
    "\n",
    "  * Es m√°s peque√±o y f√°cil de interpretar.\n",
    "  * Elimina ramas poco relevantes.\n",
    "  * Generaliza mejor a datos nuevos.\n",
    "\n",
    "Los **hiperpar√°metros de regularizaci√≥n** m√°s importantes son:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. `max_depth`\n",
    "\n",
    "L√≠mite m√°ximo de profundidad del √°rbol.\n",
    "\n",
    "* √Årbol m√°s profundo ‚Üí m√°s complejo ‚Üí m√°s riesgo de overfitting.\n",
    "* √Årbol menos profundo ‚Üí m√°s simple ‚Üí mejor generalizaci√≥n.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "```python\n",
    "clf = DecisionTreeClassifier(max_depth=5)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. `min_samples_leaf`\n",
    "\n",
    "N√∫mero m√≠nimo de muestras que debe haber en una hoja.\n",
    "\n",
    "* Obliga al √°rbol a no crear hojas con muy pocos datos.\n",
    "* Reduce el ruido y suaviza las predicciones.\n",
    "\n",
    "```python\n",
    "clf = DecisionTreeClassifier(min_samples_leaf=10)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. `min_samples_split`\n",
    "\n",
    "N√∫mero m√≠nimo de muestras necesarias para dividir un nodo.\n",
    "\n",
    "* Evita divisiones innecesarias cuando hay muy pocas muestras disponibles.\n",
    "\n",
    "```python\n",
    "clf = DecisionTreeClassifier(min_samples_split=20)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B√∫squeda autom√°tica de mejores hiperpar√°metros\n",
    "\n",
    "Podemos usar `GridSearchCV` para probar diferentes combinaciones y elegir las que mejor funcionen:\n",
    "\n",
    "``` python\n",
    "param_grid = {\n",
    "    'max_depth': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': [5, 10, 20],\n",
    "    'min_samples_split': [10, 20, 30]\n",
    "}\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "grid = GridSearchCV(clf, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto permite al alumnado ver de forma pr√°ctica c√≥mo mejorar un √°rbol sin adivinar los valores \"a ojo\".\n",
    "\n",
    "---\n",
    "\n",
    "## Post-pruning (poda tras el entrenamiento)\n",
    "\n",
    "Adem√°s de limitar el crecimiento del √°rbol desde el principio (pre-pruning), tambi√©n existe la **poda posterior**, que elimina ramas poco √∫tiles una vez entrenado el √°rbol completo.\n",
    "\n",
    "En `scikit-learn` se implementa con el par√°metro:\n",
    "\n",
    "* **`ccp_alpha`** ‚Üí controla cu√°nto se poda el √°rbol.\n",
    "\n",
    "Un valor m√°s alto = √°rbol m√°s peque√±o.\n",
    "\n",
    "Ejemplo final con un `ccp_alpha` ya elegido:\n",
    "\n",
    "``` python\n",
    "\n",
    "clf = DecisionTreeClassifier(ccp_alpha=0.02)\n",
    "clf.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "lkrTpl5eH1qQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##  **Ejercicio propuesto: Crear un modelo de √Årbol de Decisi√≥n para los mismos datasets utilizados en la pr√°ctica de Regresi√≥n Log√≠stica**\n",
    "\n",
    "El objetivo de esta actividad es que el alumnado aprenda a:\n",
    "\n",
    "* Entrenar un **√°rbol de decisi√≥n** sobre un dataset ya preprocesado.\n",
    "* Comparar su rendimiento frente al modelo de **regresi√≥n log√≠stica** visto en el notebook.\n",
    "* Identificar posibles casos de **sobreajuste** y aplicar **regularizaci√≥n**.\n",
    "* Interpretar las **reglas de decisi√≥n** y la **importancia de variables**.\n",
    "\n",
    "El alumnado debe trabajar con **los mismos datasets** utilizados en el notebook:\n",
    "\n",
    "* **Hipotiroidismo (hypothyroid.csv)** \n",
    "* **Titanic (titanic_train.csv)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PARTE 1 ‚Äì √Årbol de Decisi√≥n aplicado al dataset de Hipotiroidismo**\n",
    "\n",
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "<br>\n",
    "\n",
    "Implementar el mismo flujo del notebook (carga ‚Üí limpieza ‚Üí transformaci√≥n ‚Üí divisi√≥n)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar dataset, preprocesar, escalar y dividir en train y test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "#### **1. Crear el modelo de √°rbol b√°sico**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Evaluar rendimiento**\n",
    "\n",
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "Calcular:\n",
    "\n",
    "* Accuracy\n",
    "* Recall\n",
    "* F1-score\n",
    "* Matriz de confusi√≥n\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Detectar sobreajuste**\n",
    "\n",
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "Comprobar el score de train y test:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "<br>\n",
    "\n",
    "¬øTu modelo tiene accuracy perfecto en entrenamiento pero baja en test?\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Aplicar regularizaci√≥n**\n",
    "\n",
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "<br>\n",
    "\n",
    "Entrenar nuevos modelos cambiando:\n",
    "\n",
    "* *max_depth*\n",
    "* *min_samples_leaf*\n",
    "* *min_samples_split*\n",
    "\n",
    "Puedes usar *GridSearchCV* para probar diferentes combinaciones y elegir las que mejor funcionen\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "<br>\n",
    "\n",
    "Comparar rendimiento entre:\n",
    "\n",
    "* √Årbol sin regularizaci√≥n\n",
    "* √Årbol regularizado\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5. Interpretar importancia de variables**\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "1. ¬øQu√© variable aparece como la m√°s influyente para detectar hipotiroidismo?\n",
    "2. ¬øCoincide con lo observado con la regresi√≥n log√≠stica (coeficientes)? \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PARTE 2 ‚Äì √Årbol de Decisi√≥n aplicado al dataset del Titanic**\n",
    "\n",
    "Usando exactamente el mismo preprocesamiento del notebook de regresi√≥n log√≠stica, se pide repetir el an√°lisis:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "#### **1. Crear el modelo de √°rbol b√°sico**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Evaluar rendimiento**\n",
    "\n",
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "Calcular:\n",
    "\n",
    "* Accuracy\n",
    "* Recall\n",
    "* F1-score\n",
    "* Matriz de confusi√≥n\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "<br>\n",
    "\n",
    "1. ¬øDetecta mejor a los supervivientes que la regresi√≥n log√≠stica?\n",
    "2. ¬øTiene m√°s falsos positivos?\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Aplicar regularizaci√≥n**\n",
    "\n",
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "<br>\n",
    "\n",
    "Entrenar nuevos modelos cambiando:\n",
    "\n",
    "* *max_depth*\n",
    "* *min_samples_leaf*\n",
    "* *min_samples_split*\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "<br>\n",
    "\n",
    "¬øEl modelo mejora en generalizaci√≥n?\n",
    "\n",
    "¬øSe reduce el sobreajuste?\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Interpretar importancia de variables**\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "1. ¬øQu√© variable es la m√°s determinante para sobrevivir seg√∫n el √°rbol?\n",
    "2. ¬øCoincide con lo observado en la regresi√≥n log√≠stica (coeficiente de Sex_male)?\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5. Visualizar el √°rbol**\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "Comparar el √°rbol de decisi√≥n del modelo sin podar y el modelo podado.\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqT4CYheH1qS"
   },
   "source": [
    "#  **Ejemplo de √Årboles de Decisi√≥n para Regresi√≥n**\n",
    "\n",
    "Hasta ahora hemos visto que los **√°rboles de decisi√≥n** se utilizan principalmente para **clasificaci√≥n**, es decir, para predecir **categor√≠as** (por ejemplo: aprobado/suspenso, spam/no spam, enfermo/sano‚Ä¶).\n",
    "Sin embargo, los √°rboles de decisi√≥n tambi√©n pueden utilizarse para **regresi√≥n**, cuando lo que se desea predecir es un **valor num√©rico continuo**, como por ejemplo:\n",
    "\n",
    "* El **precio de una vivienda**\n",
    "* El **consumo el√©ctrico**\n",
    "* La **nota media de un alumno**\n",
    "* La **velocidad del viento**\n",
    "* El **importe de una factura**\n",
    "\n",
    "En este caso hablamos de **√°rboles de regresi√≥n**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  ¬øQu√© diferencia a un √°rbol de regresi√≥n de uno de clasificaci√≥n?\n",
    "\n",
    "La **estructura del √°rbol es casi id√©ntica**:\n",
    "\n",
    "* Hay una **ra√≠z**\n",
    "* Hay **nodos intermedios**\n",
    "* Hay **hojas**\n",
    "\n",
    "La diferencia principal est√° en lo que ocurre en las **hojas**:\n",
    "\n",
    "* En **clasificaci√≥n**, cada hoja devuelve una **clase**\n",
    "* En **regresi√≥n**, cada hoja devuelve un **valor num√©rico**, que suele ser:\n",
    "\n",
    "> üîπ **la media de los valores reales de las muestras que caen en esa hoja**\n",
    "\n",
    "Es decir, el √°rbol **no inventa valores**, simplemente **promedia los datos reales que ya existen**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcionamiento del √Årbol de Regresi√≥n\n",
    "\n",
    "El √°rbol funciona as√≠:\n",
    "\n",
    "1. Toma los datos de entrenamiento.\n",
    "2. Prueba todas las variables y muchos posibles cortes.\n",
    "3. Divide el conjunto en dos partes.\n",
    "4. Repite el proceso en cada parte.\n",
    "5. Se detiene cuando:\n",
    "\n",
    "   * Se alcanza una profundidad m√°xima.\n",
    "   * O hay pocas muestras en un nodo.\n",
    "   * O ya no se mejora la predicci√≥n.\n",
    "\n",
    "Cuando llega a una hoja, el valor que devuelve es:\n",
    "\n",
    "$\n",
    "\\hat{y} = \\text{media de los valores reales de ese grupo}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funci√≥n de Error: MSE (Error Cuadr√°tico Medio)\n",
    "\n",
    "En clasificaci√≥n se usa **impureza (Gini o Entrop√≠a)**.\n",
    "En regresi√≥n, el criterio de decisi√≥n es el **MSE (Mean Squared Error)**:\n",
    "\n",
    "$\n",
    "MSE = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i)^2\n",
    "$\n",
    "\n",
    "Donde:\n",
    "\n",
    "* $ y_i $ es el valor real\n",
    "* $ \\hat{y}_i $ es el valor predicho\n",
    "* $ m $ es el n√∫mero de muestras\n",
    "\n",
    "El √°rbol intenta hacer divisiones que **minimicen este error**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XE_vDa-rH1qV"
   },
   "source": [
    "---\n",
    "\n",
    "## Algoritmo CART aplicado a Regresi√≥n\n",
    "\n",
    "Scikit-learn utiliza el algoritmo **CART (Classification And Regression Tree)** tanto en clasificaci√≥n como en regresi√≥n.\n",
    "\n",
    "En regresi√≥n, el criterio de divisi√≥n es:\n",
    "\n",
    "$\n",
    "J(k,t_k) = \\frac{m_{left}}{m} MSE_{left} + \\frac{m_{right}}{m} MSE_{right}\n",
    "$\n",
    "\n",
    "Es decir:\n",
    "\n",
    "* Divide los datos en dos grupos.\n",
    "* Calcula el error en cada grupo.\n",
    "* Elige la divisi√≥n que produce **menor error total ponderado**.\n",
    "\n",
    "‚ö†Ô∏è Este algoritmo es:\n",
    "\n",
    "* **Greedy (avaro)** ‚Üí solo busca la mejor divisi√≥n local.\n",
    "* **No garantiza el √°rbol √≥ptimo global**.\n",
    "* Encontrar el √°rbol perfecto es un problema **NP‚ÄìCompleto**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBExKyRaH1qR"
   },
   "source": [
    "---\n",
    "\n",
    "## Complejidad Computacional\n",
    "\n",
    "### Predicci√≥n\n",
    "\n",
    "La predicci√≥n consiste en recorrer el √°rbol desde la ra√≠z hasta una hoja:\n",
    "\n",
    "$\n",
    "O(\\log_2(m))\n",
    "$\n",
    "\n",
    "Ventaja clave:\n",
    "\n",
    "‚úÖ Es **muy r√°pida**\n",
    "\n",
    "‚úÖ No depende del n√∫mero de variables\n",
    "\n",
    "‚úÖ Ideal para sistemas en tiempo real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KguR0QJLH1qR"
   },
   "source": [
    "\n",
    "###  Entrenamiento\n",
    "\n",
    "El entrenamiento es m√°s costoso:\n",
    "\n",
    "$\n",
    "O(n \\cdot m \\log_2(m))\n",
    "$\n",
    "\n",
    "Donde:\n",
    "\n",
    "* ( n ) ‚Üí n√∫mero de caracter√≠sticas\n",
    "* ( m ) ‚Üí n√∫mero de muestras\n",
    "\n",
    "Por eso:\n",
    "\n",
    "* Con pocos datos ‚Üí entrenamiento r√°pido\n",
    "* Con millones de datos ‚Üí entrenamiento lento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Problema Principal: Sobreajuste (Overfitting)\n",
    "\n",
    "Los √°rboles de decisi√≥n **aprenden con much√≠sima precisi√≥n**, pero eso tiene un problema:\n",
    "\n",
    "> Si no se limitan, **memorizan el ruido** de los datos.\n",
    "\n",
    "Esto provoca:\n",
    "\n",
    "* Excelente resultado en entrenamiento\n",
    "* **Mal resultado en datos nuevos**\n",
    "\n",
    "A esto lo llamamos **sobreajuste**.\n",
    "\n",
    "##  Par√°metros de Regularizaci√≥n\n",
    "\n",
    "Para evitar el sobreajuste se usan estos par√°metros:\n",
    "\n",
    "| Par√°metro           | Funci√≥n                         |\n",
    "| ------------------- | ------------------------------- |\n",
    "| `max_depth`         | Limita la profundidad del √°rbol |\n",
    "| `min_samples_leaf`  | M√≠nimo de muestras por hoja     |\n",
    "| `min_samples_split` | M√≠nimo para dividir un nodo     |\n",
    "| `max_leaf_nodes`    | M√°ximo n√∫mero de hojas          |\n",
    "\n",
    "üëâ Aumentar estos valores = menos sobreajuste\n",
    "üëâ Disminuirlos = m√°s riesgo de sobreajuste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo Pr√°ctico Interpretado\n",
    "\n",
    "Se genera un conjunto de datos con esta forma:\n",
    "\n",
    "$\n",
    "y = (x - 0.5)^2 + \\text{ruido}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yDZ9jT4gH1qS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rG3nVHySH1qS"
   },
   "outputs": [],
   "source": [
    "# Generate noisy quadratic data\n",
    "X = np.linspace(0, 1, 500)\n",
    "y = (X - 0.5)**2 + np.random.randn(500) / 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2X8oxvRxH1qT",
    "outputId": "0871d556-7cdb-4422-fba2-ec635ccb9140"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X, y, s=1.5, c='red')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamos un √°rbol con `max_depth = 2`\n",
    "\n",
    "   ‚úî Modelo simple\n",
    "   \n",
    "   ‚úî Buena generalizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8Krhab5H1qT"
   },
   "outputs": [],
   "source": [
    "tree_reg = DecisionTreeRegressor(max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JjUf2Ir_H1qT",
    "outputId": "84d3ad43-61d4-4dd7-ebf0-36b22772435c"
   },
   "outputs": [],
   "source": [
    "tree_reg.fit(X[..., None], y[..., None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqddoAtTH1qT"
   },
   "source": [
    "Visualizaci√≥n del √°rbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y7PZlgdlH1qU"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_tree(\n",
    "    tree_reg,\n",
    "    feature_names=['X'],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=10\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, el √°rbol funciona igual que en clasificaci√≥n, pero cada hoja predice un **valor num√©rico**, correspondiente al **promedio de los valores reales** de las muestras que contiene.\n",
    "\n",
    "---\n",
    "\n",
    "### Predicciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicci√≥n sobre TODOS los puntos de X\n",
    "y_pred = tree_reg.predict(X.reshape(-1,1))\n",
    "\n",
    "\n",
    "# Gr√°fica\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(X, y, s=10, color='red', alpha=0.4, label='Datos reales')\n",
    "plt.plot(X, y_pred, color='blue', linewidth=2, label='Predicci√≥n √°rbol')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamos un √°rbol sin regularizar\n",
    "\n",
    "‚ùå Memoriza el ruido\n",
    "\n",
    "‚ùå Sobreajuste muy fuerte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_no_reg = DecisionTreeRegressor()\n",
    "\n",
    "tree_no_reg.fit(X[..., None], y[..., None])\n",
    "\n",
    "# Predicci√≥n sobre TODOS los puntos de X\n",
    "y_pred2 = tree_no_reg.predict(X.reshape(-1,1))\n",
    "\n",
    "\n",
    "# Gr√°fica\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(X, y, s=10, color='red', alpha=0.4, label='Datos reales')\n",
    "plt.plot(X, y_pred2, color='blue', linewidth=2, label='Predicci√≥n √°rbol')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### √Årbol con min_samples_leaf = 10\n",
    "\n",
    "‚úÖ Modelo m√°s estable\n",
    "\n",
    "‚úÖ Predicci√≥n m√°s realista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg_10 = DecisionTreeRegressor(min_samples_leaf=10)\n",
    "\n",
    "tree_reg_10.fit(X[..., None], y[..., None])\n",
    "\n",
    "# Predicci√≥n sobre TODOS los puntos de X\n",
    "y_pred10 = tree_reg_10.predict(X.reshape(-1,1))\n",
    "\n",
    "\n",
    "# Gr√°fica\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(X, y, s=10, color='red', alpha=0.4, label='Datos reales')\n",
    "plt.plot(X, y_pred10, color='blue', linewidth=2, label='Predicci√≥n √°rbol')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ejercicio propuesto: Crear un modelo de √Årbol de Decisi√≥n para Regresi√≥n y compararlo con Regresi√≥n Lineal**\n",
    "\n",
    "El objetivo de esta actividad es que el alumnado aprenda a:\n",
    "\n",
    "* Entrenar un **modelo de √Årbol de Decisi√≥n para Regresi√≥n (`DecisionTreeRegressor`)** sobre un dataset real.\n",
    "* Comparar su rendimiento frente al modelo de **Regresi√≥n Lineal**.\n",
    "* Identificar posibles casos de **sobreajuste (overfitting)**.\n",
    "* Aplicar **regularizaci√≥n** en √°rboles de regresi√≥n.\n",
    "* Interpretar la **importancia de las variables** en un modelo basado en √°rboles.\n",
    "\n",
    "El alumnado trabajar√° con el **dataset del seguro m√©dico**, ya utilizado previamente para Regresi√≥n Lineal:\n",
    "\n",
    "* **insurance.csv** (coste de seguros m√©dicos)\n",
    "\n",
    "La variable objetivo es:\n",
    "\n",
    "* **`charges` ‚Üí coste anual del seguro**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PARTE 1 ‚Äì √Årbol de Decisi√≥n aplicado al dataset del Seguro M√©dico**\n",
    "\n",
    "\n",
    "\n",
    "Implementamos el mismo flujo del notebook (carga ‚Üí limpieza ‚Üí transformaci√≥n ‚Üí divisi√≥n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('data/insurance.csv')\n",
    "\n",
    "##Converting objects labels into categorical\n",
    "df[['sex', 'smoker', 'region']] = df[['sex', 'smoker', 'region']].astype('category')\n",
    "df.dtypes\n",
    "\n",
    "##Converting category labels into numerical using LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label = LabelEncoder()\n",
    "label.fit(df.sex.drop_duplicates())\n",
    "df.sex = label.transform(df.sex)\n",
    "label.fit(df.smoker.drop_duplicates())\n",
    "df.smoker = label.transform(df.smoker)\n",
    "label.fit(df.region.drop_duplicates())\n",
    "df.region = label.transform(df.region)\n",
    "df.dtypes\n",
    "\n",
    "X = df.drop(['charges'], axis = 1)\n",
    "y = df['charges']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Crear el modelo de √Årbol de Decisi√≥n b√°sico**\n",
    "\n",
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "<br>\n",
    "\n",
    "* Crea un modelo inicial sin regularizar:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXUn6BsDH1qd"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "<br>\n",
    "\n",
    "* Entrena el modelo con los datos de entrenamiento (*X_train*, *y_train*).\n",
    "* Realiza predicciones sobre el conjunto de test.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Evaluar el rendimiento del modelo**\n",
    "\n",
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "<br>\n",
    "\n",
    "Calcula las siguientes m√©tricas sobre el conjunto de test:\n",
    "\n",
    "* **MAE**\n",
    "* **MSE**\n",
    "* **RMSE**\n",
    "* **R¬≤**\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "<br>\n",
    "\n",
    "Representa en un gr√°fico:\n",
    "\n",
    "* *y_test* frente a *y_pred*\n",
    "\n",
    "Guarda los valores obtenidos para compararlos m√°s adelante con los otros modelos.\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Detectar sobreajuste**\n",
    "\n",
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "<br>\n",
    "\n",
    "Compara:\n",
    "\n",
    "* El rendimiento del √°rbol en **entrenamiento**\n",
    "* El rendimiento en **test**\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "<br>\n",
    "\n",
    "Responde:\n",
    "\n",
    "* ¬øExiste una diferencia grande entre ambos resultados?\n",
    "* ¬øIndica esto un posible sobreajuste?\n",
    "* ¬øPor qu√© los √°rboles tienden a sobreajustar con facilidad?\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Aplicar regularizaci√≥n al √Årbol de Decisi√≥n**\n",
    "\n",
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "<br>\n",
    "Entrena nuevos modelos **modificando hiperpar√°metros de regularizaci√≥n**, por ejemplo:\n",
    "\n",
    "* *max_depth*\n",
    "* *min_samples_leaf*\n",
    "* *min_samples_split*\n",
    "\n",
    "Puedes usar **GridSearchCV** para probar varias combinaciones y seleccionar la mejor.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "<br>\n",
    "\n",
    "Comparar el rendimiento entre:\n",
    "\n",
    "* √Årbol **sin regularizaci√≥n**\n",
    "* √Årbol **regularizado**\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "* ¬øDisminuye el sobreajuste?\n",
    "* ¬øQu√© ocurre con el valor de R¬≤?\n",
    "* ¬øCu√°l de los dos modelos generaliza mejor?\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparaci√≥n con el modelo de Regresi√≥n Lineal**\n",
    "\n",
    "<div style=\"background-color:green;color:white\">\n",
    "\n",
    "<br>\n",
    "\n",
    "Utiliza las m√©tricas obtenidas previamente con **Regresi√≥n Lineal** y construye una tabla comparativa:\n",
    "\n",
    "| Modelo                | MAE | RMSE | R¬≤ |\n",
    "| --------------------- | --- | ---- | -- |\n",
    "| Regresi√≥n Lineal      |     |      |    |\n",
    "| √Årbol sin regularizar |     |      |    |\n",
    "| √Årbol regularizado    |     |      |    |\n",
    "\n",
    "\n",
    "\n",
    "Responde razonadamente:\n",
    "\n",
    "* ¬øQu√© modelo obtiene mejor RMSE?\n",
    "* ¬øQu√© modelo generaliza mejor?\n",
    "* ¬øEn qu√© casos es preferible usar un √°rbol en lugar de una regresi√≥n lineal?\n",
    "* ¬øQu√© modelo interpretar√≠as mejor a nivel matem√°tico?\n",
    "* ¬øQu√© modelo tiene mayor capacidad de adaptaci√≥n a relaciones no lineales?\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "8.1.Supervised-DecisionTrees-RandomForest.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
